# NewsSummary-NLP-
News Summary using kobart, bert, our model

이 프로젝트는 조별 과제로 개발된 뉴스 기사 요약 및 레포트 생성 웹 애플리케이션입니다. AI-Hub에서 학습 데이터를 가져와 BERT, KoBART와 맞춤형 Seq2Seq 요약 모델을 활용하여 뉴스 기사를 요약합니다. 이 애플리케이션은 플라스크(Flask) 프레임워크를 사용하여 사용자에게 간편한 URL 입력과 요약문 생성을 제공합니다.

데이터 구조 및 학습
데이터 출처: AI-Hub
학습 데이터: 17,300 파일
검증 데이터: 4,300 파일

요약 모델
Seq2Seq 모델:
모델 구조: Attention 메커니즘을 포함한 인코더-디코더 구조
전처리: 불용어 제거, 데이터 분리, 토큰화, 정수 인코딩
학습 및 평가: 학습 과정에서 생성된 요약 모델을 통해 텍스트를 요약하고 ROUGE metric을 사용하여 성능 평가

ROUGE 성능:
ROUGE-1: 0.041
ROUGE-2: 0.017
ROUGE-L: 0.041

사전 훈련된 모델:
BERT: 사전 훈련된 BERT 모델을 사용하여 텍스트 요약
KoBART: 사전 훈련된 KoBART 모델을 사용하여 한국어 텍스트 요약

기술적 개요
데이터 전처리
불용어 제거: 주요 정보만 남기기 위해 불용어를 제거
데이터 분리: 학습 데이터와 검증 데이터를 분리하여 모델 학습
토큰화 및 정수 인코딩: 텍스트를 토큰화하고 정수로 인코딩하여 모델 입력으로 사용

Seq2Seq 모델 구조
인코더-디코더 아키텍처: 인코더는 입력 텍스트를 처리하고 디코더는 요약문을 생성
어텐션 레이어: 디코딩 과정에서 입력 텍스트의 중요 부분에 집중하여 성능 향상

웹 애플리케이션
Flask 프레임워크: 사용자에게 URL 입력과 요약문 생성을 위한 인터페이스 제공
웹 스크래핑: BeautifulSoup을 사용하여 뉴스 기사 본문을 추출

결과 및 의의

성능 평가
ROUGE Metric: ROUGE-1, ROUGE-2, ROUGE-L을 사용하여 요약 성능 평가
BERT와 KoBART 성능 우수: 사전 훈련된 모델들이 더 높은 성능을 보임

한계 및 개선점
정보의 간결한 전달: 요약문의 품질 향상 필요
URL의 편의성: 사용자가 간편하게 URL을 입력하고 요약문을 얻을 수 있음
모델 간 직관적 비교: Flask를 통해 BERT, KoBART, 맞춤형 모델 간의 요약문 비교 가능
ROUGE Metric의 한계: 표본의 한계로 인해 모델 성능 평가에 한계가 있음
요약 모델의 성능: 맞춤형 요약 모델의 성능 향상이 필요
